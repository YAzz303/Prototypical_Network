{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e75aed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import Omniglot\n",
    "from torchvision.models import resnet18\n",
    "from tqdm import tqdm\n",
    "from torchvision import datasets \n",
    "\n",
    "from easyfsl.samplers import TaskSampler\n",
    "from easyfsl.utils import plot_images, sliding_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3b63055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Flatten(start_dim=1, end_dim=-1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class PrototypicalNetworks(nn.Module):\n",
    "    def __init__(self, backbone: nn.Module):\n",
    "        super(PrototypicalNetworks, self).__init__()\n",
    "        self.backbone = backbone\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        support_images: torch.Tensor,\n",
    "        support_labels: torch.Tensor,\n",
    "        query_images: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Predict query labels using labeled support images.\n",
    "        \"\"\"\n",
    "        # Extract the features of support and query images\n",
    "        z_support = self.backbone.forward(support_images)\n",
    "        z_query = self.backbone.forward(query_images)\n",
    "\n",
    "        # Infer the number of different classes from the labels of the support set\n",
    "        n_way = len(torch.unique(support_labels))\n",
    "        # Prototype i is the mean of all instances of features corresponding to labels == i\n",
    "        z_proto = torch.cat(\n",
    "            [\n",
    "                z_support[torch.nonzero(support_labels == label)].mean(0)\n",
    "                for label in range(n_way)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Compute the euclidean distance from queries to prototypes\n",
    "        dists = torch.cdist(z_query, z_proto)\n",
    "\n",
    "        # And here is the super complicated operation to transform those distances into classification scores!\n",
    "        scores = -dists\n",
    "        return scores\n",
    "\n",
    "\n",
    "convolutional_network = resnet18(pretrained=True)\n",
    "convolutional_network.fc = nn.Flatten()\n",
    "print(convolutional_network)\n",
    "\n",
    "model = PrototypicalNetworks(convolutional_network).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c9e2739d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\AppData\\Local\\Temp\\ipykernel_13928\\4158960201.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"prototypical_networks_2.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"prototypical_networks_2.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "15dcc8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 28\n",
    "transform=transforms.Compose(\n",
    "    [\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f4290b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(self):\n",
    "    return [label for _, label in self.samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c62040d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "N_WAY = 327\n",
    "N_SHOT = 10\n",
    "N_QUERY = 0\n",
    "N_EVALUATION_TASKS = 1\n",
    "\n",
    "# Properly assign get_labels as a method (not the result)\n",
    "def get_labels(self):\n",
    "    return [label for _, label in self.samples]\n",
    "\n",
    "# Create val_set and val_loader\n",
    "val_set = datasets.ImageFolder(\"val\", transform=transform)\n",
    "\n",
    "# Assign get_labels method to val_set\n",
    "val_set.get_labels = get_labels.__get__(val_set)\n",
    "\n",
    "# Create sampler and loader\n",
    "test_sampler = TaskSampler(\n",
    "    val_set,\n",
    "    n_way=N_WAY,\n",
    "    n_shot=N_SHOT,\n",
    "    n_query=N_QUERY,\n",
    "    n_tasks=N_EVALUATION_TASKS\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_set,\n",
    "    batch_sampler=test_sampler,\n",
    "    collate_fn=test_sampler.episodic_collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4d47fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def compute_prototypes(backbone, support_images, support_labels, n_way):\n",
    "    backbone.eval()\n",
    "    with torch.no_grad():\n",
    "        z_support = backbone(support_images)  # [num_support, embedding_dim]\n",
    "\n",
    "    prototypes = []\n",
    "    for c in range(n_way):\n",
    "        class_embeddings = z_support[support_labels == c]\n",
    "        proto = class_embeddings.mean(0)\n",
    "        prototypes.append(proto)\n",
    "\n",
    "    prototypes = torch.stack(prototypes)  # [n_way, embedding_dim]\n",
    "    return prototypes\n",
    "\n",
    "def save_prototypes(prototypes, filepath):\n",
    "    torch.save(prototypes.cpu(), filepath)\n",
    "    print(f\"Prototypes saved to {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "329e0b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support images shape: torch.Size([3270, 3, 28, 28])\n",
      "Support labels shape: torch.Size([3270])\n",
      "Unique classes in support labels: tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265,\n",
      "        266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279,\n",
      "        280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293,\n",
      "        294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
      "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
      "        322, 323, 324, 325, 326], device='cuda:0')\n",
      "Prototypes shape: torch.Size([327, 512])\n"
     ]
    }
   ],
   "source": [
    "# Get one episodic batch from val_loader\n",
    "batch = next(iter(val_loader))\n",
    "\n",
    "# Extract support set images and labels from the tuple\n",
    "support_images = batch[0].to(model.backbone.conv1.weight.device)  # shape: [N_WAY * N_SHOT, C, H, W]\n",
    "support_labels = batch[1].to(model.backbone.conv1.weight.device)  # shape: [N_WAY * N_SHOT]\n",
    "\n",
    "# Convert grayscale (1 channel) images to 3 channels for ResNet\n",
    "if support_images.shape[1] == 1:\n",
    "\tsupport_images = support_images.repeat(1, 3, 1, 1)\n",
    "\n",
    "print(\"Support images shape:\", support_images.shape)\n",
    "print(\"Support labels shape:\", support_labels.shape)\n",
    "print(\"Unique classes in support labels:\", torch.unique(support_labels))\n",
    "\n",
    "# Compute prototypes by averaging embeddings per class\n",
    "prototypes = compute_prototypes(model.backbone, support_images, support_labels, n_way=N_WAY)\n",
    "\n",
    "print(\"Prototypes shape:\", prototypes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7b0bb4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prototypes saved to prototypes_resnet.pth\n"
     ]
    }
   ],
   "source": [
    "save_prototypes(prototypes, \"prototypes_resnet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "707e1756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 0: Label 0 -> bhujimol-a\n",
      "Index 1: Label 1 -> bhujimol-aa\n",
      "Index 2: Label 2 -> bhujimol-ah\n",
      "Index 3: Label 3 -> bhujimol-ai\n",
      "Index 4: Label 4 -> bhujimol-am\n",
      "Index 5: Label 5 -> bhujimol-au\n",
      "Index 6: Label 6 -> bhujimol-ba\n",
      "Index 7: Label 7 -> bhujimol-bha\n",
      "Index 8: Label 8 -> bhujimol-ca\n",
      "Index 9: Label 9 -> bhujimol-cha\n",
      "Index 10: Label 10 -> bhujimol-da\n",
      "Index 11: Label 11 -> bhujimol-daa\n",
      "Index 12: Label 12 -> bhujimol-dha\n",
      "Index 13: Label 13 -> bhujimol-dhaa\n",
      "Index 14: Label 14 -> bhujimol-e\n",
      "Index 15: Label 15 -> bhujimol-ga\n",
      "Index 16: Label 16 -> bhujimol-gha\n",
      "Index 17: Label 17 -> bhujimol-gja\n",
      "Index 18: Label 18 -> bhujimol-ha\n",
      "Index 19: Label 19 -> bhujimol-i\n",
      "Index 20: Label 20 -> bhujimol-ii\n",
      "Index 21: Label 21 -> bhujimol-ja\n",
      "Index 22: Label 22 -> bhujimol-jha\n",
      "Index 23: Label 23 -> bhujimol-ka\n",
      "Index 24: Label 24 -> bhujimol-kha\n",
      "Index 25: Label 25 -> bhujimol-ksa\n",
      "Index 26: Label 26 -> bhujimol-la\n",
      "Index 27: Label 27 -> bhujimol-lr\n",
      "Index 28: Label 28 -> bhujimol-lrr\n",
      "Index 29: Label 29 -> bhujimol-ma\n",
      "Index 30: Label 30 -> bhujimol-na\n",
      "Index 31: Label 31 -> bhujimol-naa\n",
      "Index 32: Label 32 -> bhujimol-naaa\n",
      "Index 33: Label 33 -> bhujimol-naaaaa\n",
      "Index 34: Label 34 -> bhujimol-o\n",
      "Index 35: Label 35 -> bhujimol-pa\n",
      "Index 36: Label 36 -> bhujimol-pha\n",
      "Index 37: Label 37 -> bhujimol-r\n",
      "Index 38: Label 38 -> bhujimol-ra\n",
      "Index 39: Label 39 -> bhujimol-rr\n",
      "Index 40: Label 40 -> bhujimol-sa\n",
      "Index 41: Label 41 -> bhujimol-saa\n",
      "Index 42: Label 42 -> bhujimol-saaa\n",
      "Index 43: Label 43 -> bhujimol-ta\n",
      "Index 44: Label 44 -> bhujimol-taa\n",
      "Index 45: Label 45 -> bhujimol-tha\n",
      "Index 46: Label 46 -> bhujimol-thaa\n",
      "Index 47: Label 47 -> bhujimol-tra\n",
      "Index 48: Label 48 -> bhujimol-u\n",
      "Index 49: Label 49 -> bhujimol-uu\n",
      "Index 50: Label 50 -> bhujimol-va\n",
      "Index 51: Label 51 -> bhujimol-ya\n",
      "Index 52: Label 52 -> brahmi-a\n",
      "Index 53: Label 53 -> brahmi-aa\n",
      "Index 54: Label 54 -> brahmi-am\n",
      "Index 55: Label 55 -> brahmi-ba\n",
      "Index 56: Label 56 -> brahmi-bha\n",
      "Index 57: Label 57 -> brahmi-ca\n",
      "Index 58: Label 58 -> brahmi-cha\n",
      "Index 59: Label 59 -> brahmi-da\n",
      "Index 60: Label 60 -> brahmi-dda\n",
      "Index 61: Label 61 -> brahmi-ddha\n",
      "Index 62: Label 62 -> brahmi-dha\n",
      "Index 63: Label 63 -> brahmi-e\n",
      "Index 64: Label 64 -> brahmi-ga\n",
      "Index 65: Label 65 -> brahmi-gha\n",
      "Index 66: Label 66 -> brahmi-ha\n",
      "Index 67: Label 67 -> brahmi-i\n",
      "Index 68: Label 68 -> brahmi-ja\n",
      "Index 69: Label 69 -> brahmi-jah\n",
      "Index 70: Label 70 -> brahmi-jha\n",
      "Index 71: Label 71 -> brahmi-ka\n",
      "Index 72: Label 72 -> brahmi-kha\n",
      "Index 73: Label 73 -> brahmi-ksa\n",
      "Index 74: Label 74 -> brahmi-la\n",
      "Index 75: Label 75 -> brahmi-ma\n",
      "Index 76: Label 76 -> brahmi-na\n",
      "Index 77: Label 77 -> brahmi-naa\n",
      "Index 78: Label 78 -> brahmi-nna\n",
      "Index 79: Label 79 -> brahmi-nnaa\n",
      "Index 80: Label 80 -> brahmi-o\n",
      "Index 81: Label 81 -> brahmi-pa\n",
      "Index 82: Label 82 -> brahmi-pha\n",
      "Index 83: Label 83 -> brahmi-ra\n",
      "Index 84: Label 84 -> brahmi-sa\n",
      "Index 85: Label 85 -> brahmi-saa\n",
      "Index 86: Label 86 -> brahmi-ssa\n",
      "Index 87: Label 87 -> brahmi-ta\n",
      "Index 88: Label 88 -> brahmi-taa\n",
      "Index 89: Label 89 -> brahmi-tha\n",
      "Index 90: Label 90 -> brahmi-tra\n",
      "Index 91: Label 91 -> brahmi-ttha\n",
      "Index 92: Label 92 -> brahmi-u\n",
      "Index 93: Label 93 -> brahmi-va\n",
      "Index 94: Label 94 -> brahmi-ya\n",
      "Index 95: Label 95 -> kirat_a\n",
      "Index 96: Label 96 -> kirat_aa\n",
      "Index 97: Label 97 -> kirat_ah\n",
      "Index 98: Label 98 -> kirat_ai\n",
      "Index 99: Label 99 -> kirat_am\n",
      "Index 100: Label 100 -> kirat_ba\n",
      "Index 101: Label 101 -> kirat_bha\n",
      "Index 102: Label 102 -> kirat_ca\n",
      "Index 103: Label 103 -> kirat_cha\n",
      "Index 104: Label 104 -> kirat_daa\n",
      "Index 105: Label 105 -> kirat_dhaa\n",
      "Index 106: Label 106 -> kirat_e\n",
      "Index 107: Label 107 -> kirat_ga\n",
      "Index 108: Label 108 -> kirat_gha\n",
      "Index 109: Label 109 -> kirat_gja\n",
      "Index 110: Label 110 -> kirat_ha\n",
      "Index 111: Label 111 -> kirat_ii\n",
      "Index 112: Label 112 -> kirat_ja\n",
      "Index 113: Label 113 -> kirat_jha\n",
      "Index 114: Label 114 -> kirat_ka\n",
      "Index 115: Label 115 -> kirat_kha\n",
      "Index 116: Label 116 -> kirat_la\n",
      "Index 117: Label 117 -> kirat_ma\n",
      "Index 118: Label 118 -> kirat_na\n",
      "Index 119: Label 119 -> kirat_naa\n",
      "Index 120: Label 120 -> kirat_naaaa\n",
      "Index 121: Label 121 -> kirat_o\n",
      "Index 122: Label 122 -> kirat_pa\n",
      "Index 123: Label 123 -> kirat_pha\n",
      "Index 124: Label 124 -> kirat_ra\n",
      "Index 125: Label 125 -> kirat_sa\n",
      "Index 126: Label 126 -> kirat_saa\n",
      "Index 127: Label 127 -> kirat_saaa\n",
      "Index 128: Label 128 -> kirat_ta\n",
      "Index 129: Label 129 -> kirat_thaa\n",
      "Index 130: Label 130 -> kirat_tra\n",
      "Index 131: Label 131 -> kirat_uu\n",
      "Index 132: Label 132 -> kirat_va\n",
      "Index 133: Label 133 -> kirat_ya\n",
      "Index 134: Label 134 -> lichhavi_a\n",
      "Index 135: Label 135 -> lichhavi_aa\n",
      "Index 136: Label 136 -> lichhavi_ai\n",
      "Index 137: Label 137 -> lichhavi_ba\n",
      "Index 138: Label 138 -> lichhavi_bha\n",
      "Index 139: Label 139 -> lichhavi_ca\n",
      "Index 140: Label 140 -> lichhavi_cha\n",
      "Index 141: Label 141 -> lichhavi_da\n",
      "Index 142: Label 142 -> lichhavi_dda\n",
      "Index 143: Label 143 -> lichhavi_ddha\n",
      "Index 144: Label 144 -> lichhavi_dha\n",
      "Index 145: Label 145 -> lichhavi_e\n",
      "Index 146: Label 146 -> lichhavi_ga\n",
      "Index 147: Label 147 -> lichhavi_gha\n",
      "Index 148: Label 148 -> lichhavi_ha\n",
      "Index 149: Label 149 -> lichhavi_i\n",
      "Index 150: Label 150 -> lichhavi_ja\n",
      "Index 151: Label 151 -> lichhavi_jha\n",
      "Index 152: Label 152 -> lichhavi_ka\n",
      "Index 153: Label 153 -> lichhavi_kha\n",
      "Index 154: Label 154 -> lichhavi_la\n",
      "Index 155: Label 155 -> lichhavi_ma\n",
      "Index 156: Label 156 -> lichhavi_na\n",
      "Index 157: Label 157 -> lichhavi_naa\n",
      "Index 158: Label 158 -> lichhavi_nna\n",
      "Index 159: Label 159 -> lichhavi_nnaa\n",
      "Index 160: Label 160 -> lichhavi_pa\n",
      "Index 161: Label 161 -> lichhavi_pha\n",
      "Index 162: Label 162 -> lichhavi_ra\n",
      "Index 163: Label 163 -> lichhavi_sa\n",
      "Index 164: Label 164 -> lichhavi_saa\n",
      "Index 165: Label 165 -> lichhavi_ssa\n",
      "Index 166: Label 166 -> lichhavi_ta\n",
      "Index 167: Label 167 -> lichhavi_tha\n",
      "Index 168: Label 168 -> lichhavi_tta\n",
      "Index 169: Label 169 -> lichhavi_ttha\n",
      "Index 170: Label 170 -> lichhavi_va\n",
      "Index 171: Label 171 -> lichhavi_ya\n",
      "Index 172: Label 172 -> maithili_a\n",
      "Index 173: Label 173 -> maithili_aa\n",
      "Index 174: Label 174 -> maithili_ah\n",
      "Index 175: Label 175 -> maithili_ai\n",
      "Index 176: Label 176 -> maithili_am\n",
      "Index 177: Label 177 -> maithili_au\n",
      "Index 178: Label 178 -> maithili_ba\n",
      "Index 179: Label 179 -> maithili_bha\n",
      "Index 180: Label 180 -> maithili_ca\n",
      "Index 181: Label 181 -> maithili_cha\n",
      "Index 182: Label 182 -> maithili_da\n",
      "Index 183: Label 183 -> maithili_daa\n",
      "Index 184: Label 184 -> maithili_dha\n",
      "Index 185: Label 185 -> maithili_dhaa\n",
      "Index 186: Label 186 -> maithili_e\n",
      "Index 187: Label 187 -> maithili_ga\n",
      "Index 188: Label 188 -> maithili_gha\n",
      "Index 189: Label 189 -> maithili_gja\n",
      "Index 190: Label 190 -> maithili_ha\n",
      "Index 191: Label 191 -> maithili_i\n",
      "Index 192: Label 192 -> maithili_ii\n",
      "Index 193: Label 193 -> maithili_ja\n",
      "Index 194: Label 194 -> maithili_jha\n",
      "Index 195: Label 195 -> maithili_ka\n",
      "Index 196: Label 196 -> maithili_kha\n",
      "Index 197: Label 197 -> maithili_ksa\n",
      "Index 198: Label 198 -> maithili_la\n",
      "Index 199: Label 199 -> maithili_lr\n",
      "Index 200: Label 200 -> maithili_lrr\n",
      "Index 201: Label 201 -> maithili_ma\n",
      "Index 202: Label 202 -> maithili_na\n",
      "Index 203: Label 203 -> maithili_naa\n",
      "Index 204: Label 204 -> maithili_naaa\n",
      "Index 205: Label 205 -> maithili_naaaa\n",
      "Index 206: Label 206 -> maithili_o\n",
      "Index 207: Label 207 -> maithili_pa\n",
      "Index 208: Label 208 -> maithili_pha\n",
      "Index 209: Label 209 -> maithili_r\n",
      "Index 210: Label 210 -> maithili_ra\n",
      "Index 211: Label 211 -> maithili_rr\n",
      "Index 212: Label 212 -> maithili_sa\n",
      "Index 213: Label 213 -> maithili_saa\n",
      "Index 214: Label 214 -> maithili_saaa\n",
      "Index 215: Label 215 -> maithili_ta\n",
      "Index 216: Label 216 -> maithili_taa\n",
      "Index 217: Label 217 -> maithili_tha\n",
      "Index 218: Label 218 -> maithili_thaa\n",
      "Index 219: Label 219 -> maithili_tra\n",
      "Index 220: Label 220 -> maithili_u\n",
      "Index 221: Label 221 -> maithili_uu\n",
      "Index 222: Label 222 -> maithili_va\n",
      "Index 223: Label 223 -> maithili_ya\n",
      "Index 224: Label 224 -> nandanagiri-a\n",
      "Index 225: Label 225 -> nandanagiri-aa\n",
      "Index 226: Label 226 -> nandanagiri-ah\n",
      "Index 227: Label 227 -> nandanagiri-ai\n",
      "Index 228: Label 228 -> nandanagiri-am\n",
      "Index 229: Label 229 -> nandanagiri-au\n",
      "Index 230: Label 230 -> nandanagiri-ba\n",
      "Index 231: Label 231 -> nandanagiri-bha\n",
      "Index 232: Label 232 -> nandanagiri-ca\n",
      "Index 233: Label 233 -> nandanagiri-cha\n",
      "Index 234: Label 234 -> nandanagiri-daa\n",
      "Index 235: Label 235 -> nandanagiri-dha\n",
      "Index 236: Label 236 -> nandanagiri-dhaa\n",
      "Index 237: Label 237 -> nandanagiri-e\n",
      "Index 238: Label 238 -> nandanagiri-ga\n",
      "Index 239: Label 239 -> nandanagiri-gha\n",
      "Index 240: Label 240 -> nandanagiri-gja\n",
      "Index 241: Label 241 -> nandanagiri-ha\n",
      "Index 242: Label 242 -> nandanagiri-i\n",
      "Index 243: Label 243 -> nandanagiri-ii\n",
      "Index 244: Label 244 -> nandanagiri-ja\n",
      "Index 245: Label 245 -> nandanagiri-jha\n",
      "Index 246: Label 246 -> nandanagiri-ka\n",
      "Index 247: Label 247 -> nandanagiri-kha\n",
      "Index 248: Label 248 -> nandanagiri-ksa\n",
      "Index 249: Label 249 -> nandanagiri-la\n",
      "Index 250: Label 250 -> nandanagiri-lr\n",
      "Index 251: Label 251 -> nandanagiri-lrr\n",
      "Index 252: Label 252 -> nandanagiri-ma\n",
      "Index 253: Label 253 -> nandanagiri-na\n",
      "Index 254: Label 254 -> nandanagiri-naa\n",
      "Index 255: Label 255 -> nandanagiri-naaa\n",
      "Index 256: Label 256 -> nandanagiri-naaaa\n",
      "Index 257: Label 257 -> nandanagiri-o\n",
      "Index 258: Label 258 -> nandanagiri-pa\n",
      "Index 259: Label 259 -> nandanagiri-pha\n",
      "Index 260: Label 260 -> nandanagiri-r\n",
      "Index 261: Label 261 -> nandanagiri-ra\n",
      "Index 262: Label 262 -> nandanagiri-rr\n",
      "Index 263: Label 263 -> nandanagiri-sa\n",
      "Index 264: Label 264 -> nandanagiri-saa\n",
      "Index 265: Label 265 -> nandanagiri-saaa\n",
      "Index 266: Label 266 -> nandanagiri-ta\n",
      "Index 267: Label 267 -> nandanagiri-taa\n",
      "Index 268: Label 268 -> nandanagiri-tha\n",
      "Index 269: Label 269 -> nandanagiri-thaa\n",
      "Index 270: Label 270 -> nandanagiri-tra\n",
      "Index 271: Label 271 -> nandanagiri-u\n",
      "Index 272: Label 272 -> nandanagiri-uu\n",
      "Index 273: Label 273 -> nandanagiri-va\n",
      "Index 274: Label 274 -> nandanagiri-ya\n",
      "Index 275: Label 275 -> tibetan-a\n",
      "Index 276: Label 276 -> tibetan-aa\n",
      "Index 277: Label 277 -> tibetan-ah\n",
      "Index 278: Label 278 -> tibetan-ai\n",
      "Index 279: Label 279 -> tibetan-am\n",
      "Index 280: Label 280 -> tibetan-au\n",
      "Index 281: Label 281 -> tibetan-ba\n",
      "Index 282: Label 282 -> tibetan-bha\n",
      "Index 283: Label 283 -> tibetan-ca\n",
      "Index 284: Label 284 -> tibetan-cha\n",
      "Index 285: Label 285 -> tibetan-da\n",
      "Index 286: Label 286 -> tibetan-daa\n",
      "Index 287: Label 287 -> tibetan-dha\n",
      "Index 288: Label 288 -> tibetan-dhaa\n",
      "Index 289: Label 289 -> tibetan-e\n",
      "Index 290: Label 290 -> tibetan-ga\n",
      "Index 291: Label 291 -> tibetan-gha\n",
      "Index 292: Label 292 -> tibetan-gja\n",
      "Index 293: Label 293 -> tibetan-ha\n",
      "Index 294: Label 294 -> tibetan-i\n",
      "Index 295: Label 295 -> tibetan-ii\n",
      "Index 296: Label 296 -> tibetan-ja\n",
      "Index 297: Label 297 -> tibetan-jha\n",
      "Index 298: Label 298 -> tibetan-ka\n",
      "Index 299: Label 299 -> tibetan-kha\n",
      "Index 300: Label 300 -> tibetan-ksa\n",
      "Index 301: Label 301 -> tibetan-la\n",
      "Index 302: Label 302 -> tibetan-lr\n",
      "Index 303: Label 303 -> tibetan-lrr\n",
      "Index 304: Label 304 -> tibetan-ma\n",
      "Index 305: Label 305 -> tibetan-na\n",
      "Index 306: Label 306 -> tibetan-naa\n",
      "Index 307: Label 307 -> tibetan-naaa\n",
      "Index 308: Label 308 -> tibetan-naaaa\n",
      "Index 309: Label 309 -> tibetan-o\n",
      "Index 310: Label 310 -> tibetan-pa\n",
      "Index 311: Label 311 -> tibetan-pha\n",
      "Index 312: Label 312 -> tibetan-r\n",
      "Index 313: Label 313 -> tibetan-ra\n",
      "Index 314: Label 314 -> tibetan-rr\n",
      "Index 315: Label 315 -> tibetan-sa\n",
      "Index 316: Label 316 -> tibetan-saa\n",
      "Index 317: Label 317 -> tibetan-saaa\n",
      "Index 318: Label 318 -> tibetan-ta\n",
      "Index 319: Label 319 -> tibetan-taa\n",
      "Index 320: Label 320 -> tibetan-tha\n",
      "Index 321: Label 321 -> tibetan-thaa\n",
      "Index 322: Label 322 -> tibetan-tra\n",
      "Index 323: Label 323 -> tibetan-u\n",
      "Index 324: Label 324 -> tibetan-uu\n",
      "Index 325: Label 325 -> tibetan-va\n",
      "Index 326: Label 326 -> tibetan-ya\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# The fifth element of the batch tuple contains the list of label indices in order\n",
    "index_to_label = {idx: label for idx, label in enumerate(batch[4])}\n",
    "# Print mapping from index to label name\n",
    "for idx, label_idx in index_to_label.items():\n",
    "    label_name = val_set.classes[label_idx]\n",
    "    print(f\"Index {idx}: Label {label_idx} -> {label_name}\")\n",
    "    # Save mapping as CSV instead of printing\n",
    "    with open(\"index_to_label.csv\", \"w\", encoding=\"utf-8\", newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"Index\", \"Label Index\", \"Label Name\"])\n",
    "        for idx, label_idx in index_to_label.items():\n",
    "            label_name = val_set.classes[label_idx]\n",
    "            writer.writerow([idx, label_idx, label_name])\n",
    "with open(\"index_to_label.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    # Create a dictionary mapping index to label name\n",
    "    index_to_label_name = {idx: val_set.classes[label_idx] for idx, label_idx in index_to_label.items()}\n",
    "    # Save as JSON\n",
    "    json.dump(index_to_label_name, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0375ac43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
